import os
import time
import numpy as np
import sounddevice as sd
from scipy.io import wavfile
import librosa

# åƒæ•¸è¨­å®š
fs = 16000  # å–æ¨£ç‡
chunk_duration = 2  # æ¯æ¬¡éŒ„éŸ³çš„å€æ®µé•·åº¦ï¼ˆç§’ï¼‰
clip_duration = 1.0  # è¦è£åˆ‡çš„ç›®æ¨™èªéŸ³é•·åº¦
output_folder = 'clips'
os.makedirs(output_folder, exist_ok=True)

def trim_speech(audio, sr, target_duration=1.0, top_db=20):
    intervals = librosa.effects.split(audio, top_db=top_db)
    clips = []
    for start, end in intervals:
        segment = audio[start:end]
        if len(segment) < int(sr * 0.2):  # å¿½ç•¥å¤ªçŸ­çš„ç‰‡æ®µï¼ˆé¿å…é›œéŸ³ï¼‰
            continue
        target_len = int(target_duration * sr)
        if len(segment) < target_len:
            segment = np.pad(segment, (0, target_len - len(segment)))
        else:
            segment = segment[:target_len]
        clips.append(segment)
    return clips

def record_loop():
    idx = 1
    print("ğŸ™ï¸ æŒçºŒéŒ„éŸ³ä¸­ï¼ŒæŒ‰ Ctrl+C åœæ­¢")
    try:
        while True:
            print(f"âºï¸ éŒ„è£½ {chunk_duration} ç§’...")
            audio = sd.rec(int(fs * chunk_duration), samplerate=fs, channels=1, dtype='int16')
            sd.wait()
            y = audio.flatten().astype(np.float32) / 32768.0  # æ­£è¦åŒ–ç‚º float32 [-1,1]
            clips = trim_speech(y, fs, target_duration=clip_duration)
            print(f"ğŸ§ åµæ¸¬åˆ° {len(clips)} æ®µèªéŸ³")
            for clip in clips:
                wav_path = os.path.join(output_folder, f"ENoff-{idx:03d}.wav")
                wavfile.write(wav_path, fs, (clip * 32767).astype(np.int16))
                print(f"âœ… å„²å­˜ {wav_path}")
                idx += 1
    except KeyboardInterrupt:
        print("\nğŸ›‘ éŒ„éŸ³çµæŸ")

if __name__ == "__main__":
    record_loop()