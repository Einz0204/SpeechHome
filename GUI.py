import sounddevice as sd  # ç”¨æ–¼éŒ„éŸ³
import scipy.io.wavfile as wavfile  # ç”¨æ–¼è®€å¯« WAV æª”æ¡ˆ
import librosa  # ç”¨æ–¼éŸ³è¨Šè™•ç†ï¼ˆå»éœéŸ³ã€æ“·å–ç‰¹å¾µç­‰ï¼‰
import numpy as np  # ç”¨æ–¼æ•¸å€¼é‹ç®—\ import tensorflow as tf  # ç”¨æ–¼è¼‰å…¥åŠæ¨è«– TensorFlow æ¨¡å‹
import tkinter as tk  # ç”¨æ–¼å»ºç«‹ GUI
import tensorflow as tf  # ç”¨æ–¼è¼‰å…¥åŠæ¨è«– TensorFlow æ¨¡å‹
import time  # ç”¨æ–¼è¨ˆç®—æ™‚é–“
import threading  # ç”¨æ–¼åŸ·è¡ŒéåŒæ­¥çš„è¾¨è­˜æµç¨‹
import os  # ç”¨æ–¼æª”æ¡ˆèˆ‡è·¯å¾‘æ“ä½œ
from collections import deque  # é›™å‘ä½‡åˆ—ï¼Œç”¨æ–¼æ»‘å‹•è¦–çª—ç·©è¡
from scipy.io.wavfile import write  # å¿«é€Ÿå¯«å‡º WAV æª”æ¡ˆ

# === åƒæ•¸è¨­å®š ===
fs_activation    = 16000    # éŒ„è£½å•Ÿå‹•è©æ™‚çš„å–æ¨£ç‡ (Hz)
fs_command       = 16000    # éŒ„è£½æŒ‡ä»¤æ™‚çš„å–æ¨£ç‡ (Hz)
window_length    = 2        # æ»‘å‹•è¦–çª—é•·åº¦ (ç§’)ï¼Œç”¨æ–¼æŒ‡ä»¤è¾¨è­˜æ™‚çš„ç·©è¡
step_duration    = 0.7      # æ¯æ¬¡éŒ„éŸ³çš„æ™‚é–“ç‰‡é•·åº¦ (ç§’)
timeout_command  = 20.0     # æœ€å¤šç­‰å¾…æŒ‡ä»¤çš„ç¸½æ™‚é•· (ç§’)
activation_dur   = 3.0      # éŒ„è£½å•Ÿå‹•è©çš„æ™‚é–“é•·åº¦ (ç§’)
record_file      = 'raw.wav'  # è‡¨æ™‚éŒ„éŸ³æª”æ¡ˆåç¨±
model_path       = os.path.join('classifier', 'cnn_model.h5')  # å·²è¨“ç·´æ¨¡å‹æª”æ¡ˆè·¯å¾‘
test_dir         = 'test_inputs'  # ç”¨æ–¼å„²å­˜æ¸¬è©¦åŠä¸­é–“æª”æ¡ˆçš„è³‡æ–™å¤¾

# === ä¿¡å¿ƒåº¦ & æ¨™ç±¤è¨­å®š ===
CONF_THRESHOLD      = 0.85  # åŸ·è¡ŒæŒ‡ä»¤çš„æœ€ä½ä¿¡å¿ƒé–€æª»
EXECUTABLE_COMMANDS = ["é–‹ç‡ˆ", "é—œç‡ˆ"]  # è‹¥è¾¨è­˜åˆ°å…¶ä¸­æŒ‡ä»¤ä¸”ä¿¡å¿ƒè¶³å¤ ï¼Œå„ªå…ˆåŸ·è¡Œ
NON_EXECUTABLE_TAGS = ["UNKNOWN", "Noise"]  # é€™å…©é¡ä¸ç®¡ä¿¡å¿ƒå¤šé«˜éƒ½ä¸åŸ·è¡Œ

# ç¢ºä¿ç”¨ä¾†å­˜æª”æ¡ˆçš„è³‡æ–™å¤¾å­˜åœ¨
os.makedirs(test_dir, exist_ok=True)

# === è¼‰å…¥æ‰€æœ‰æŒ‡ä»¤æ¨™ç±¤ ===
with open("classifier/labels.txt", "r", encoding="utf-8") as f:
    # labels.txt æ¯è¡Œä¸€å€‹æ¨™ç±¤
    COMMANDS = [l.strip() for l in f]

# === è¼‰å…¥æ¨¡å‹ (compile=False å¯åŠ å¿«è¼‰å…¥) ===
MODEL = tf.keras.models.load_model(model_path, compile=False)

# === åŠŸèƒ½å‡½æ•¸ï¼šéŒ„éŸ³ä¸¦å¯«å…¥æª”æ¡ˆ ===
def record_audio_to_file(sr, duration, filename):
    """
    éŒ„è£½ä¸€æ®µéŸ³è¨Šï¼Œä¸¦ä»¥ int16 æ ¼å¼å­˜ç‚º WAVã€‚
    sr: å–æ¨£ç‡ï¼Œduration: éŒ„éŸ³ç§’æ•¸ï¼Œfilename: è¼¸å‡ºæª”æ¡ˆ
    """
    audio = sd.rec(int(sr * duration), samplerate=sr, channels=1, dtype='int16')
    sd.wait()
    wavfile.write(filename, sr, audio)

# === åŠŸèƒ½å‡½æ•¸ï¼šéŒ„è£½éŸ³è¨Šç‰‡æ®µä¸¦å›å‚³æ­£è¦åŒ–å¾Œçš„ numpy é™£åˆ— ===
def record_chunk(sr, duration):
    """
    éŒ„è£½ä¸€æ®µéŸ³è¨Šä¸¦å›å‚³ float32 é™£åˆ—ï¼Œç¯„åœ [-1, 1]
    """
    audio = sd.rec(int(sr * duration), samplerate=sr, channels=1, dtype='int16')
    sd.wait()
    return audio.flatten().astype(np.float32) / 32767.0

# === åŠŸèƒ½å‡½æ•¸ï¼šå¾æª”æ¡ˆå»é™¤éœéŸ³ä¸¦å›ºå®šé•·åº¦ ===
def trim_speech_from_file(fn, sr, target_dur=1.5):
    """
    è®€å…¥æª”æ¡ˆ fnï¼Œå»é™¤éœé»˜ç‰‡æ®µï¼Œä¸¦ pad æˆ–æˆªæ–·è‡³ target_durã€‚
    å›å‚³ç›®æ¨™é•·åº¦çš„ 1D é™£åˆ—ï¼Œè‹¥ç„¡èªéŸ³å‰‡å›å‚³ Noneã€‚
    """
    y, _ = librosa.load(fn, sr=sr)
    # æ‰¾å‡ºééœéŸ³å€é–“
    intervals = librosa.effects.split(y, top_db=20)
    if not len(intervals):
        return None  # æ²’èªéŸ³
    # åˆä½µæ‰€æœ‰ééœéŸ³ç‰‡æ®µ
    s = np.concatenate([y[start:end] for start, end in intervals])
    L = int(target_dur * sr)
    # æˆªæ–·æˆ–è£œé›¶
    return s[:L] if len(s) >= L else np.pad(s, (0, L-len(s)))

# === åŠŸèƒ½å‡½æ•¸ï¼šå¾é™£åˆ—å»é™¤éœéŸ³ä¸¦å›ºå®šé•·åº¦ ===
def trim_speech_from_array(y, sr, target_dur=1.5):
    """
    èˆ‡ trim_speech_from_file ç›¸åŒï¼Œä½†è¼¸å…¥ç‚ºå·²è®€å…¥çš„ y é™£åˆ—ã€‚
    """
    intervals = librosa.effects.split(y, top_db=20)
    if not len(intervals):
        return None
    s = np.concatenate([y[start:end] for start, end in intervals])
    L = int(target_dur * sr)
    return s[:L] if len(s) >= L else np.pad(s, (0, L-len(s)))

# === åŠŸèƒ½å‡½æ•¸ï¼šè£œé½Šæˆ–æˆªæ–· MFCC åˆ°å›ºå®šæ¬„æ•¸ ===
def fix_mfcc_length(mfcc, target_frames=32):
    """
    å°‡ç¬¬ 2 ç¶­ (æ™‚é–“è»¸) pad æˆ–æˆªæ–·è‡³ target_framesã€‚
    """
    if mfcc.shape[1] < target_frames:
        pad_amount = target_frames - mfcc.shape[1]
        return np.pad(mfcc, ((0,0),(0,pad_amount)), mode='constant')
    return mfcc[:, :target_frames]

# === åŠŸèƒ½å‡½æ•¸ï¼šæ¨¡å‹æ¨è«– ===
def predict_command(signal, sr):
    """
    å°è¼¸å…¥çš„éŸ³è¨Šè¨Šè™Ÿ signal åŸ·è¡Œ MFCC -> æ¨¡å‹é æ¸¬ -> å›å‚³ (label, confidence)
    """
    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=40)
    mfcc = fix_mfcc_length(mfcc, target_frames=32)
    mfcc = mfcc[..., np.newaxis]  # (n_mfcc, time, 1)
    mfcc = np.expand_dims(mfcc, 0)  # (1, n_mfcc, time, 1)
    pred = MODEL.predict(mfcc, verbose=0)[0]
    idx, conf = int(np.argmax(pred)), float(np.max(pred))
    return COMMANDS[idx], conf

# === ç­‰å¾…å•Ÿå‹•è© ===
def listen_for_activation():
    """
    é‡è¤‡éŒ„éŸ³èˆ‡æ¨è«–ï¼Œç›´åˆ°åµæ¸¬åˆ°ã€Œå•Ÿå‹•ã€ä¸”ä¿¡å¿ƒ >= 0.8
    """
    result_var.set("ğŸ§ ç­‰å¾…ã€å•Ÿå‹•ã€â€¦")
    while True:
        record_audio_to_file(fs_activation, activation_dur, record_file)
        sig = trim_speech_from_file(record_file, fs_activation)
        if sig is None:
            continue
        cmd, conf = predict_command(sig, fs_activation)
        if cmd == "å•Ÿå‹•" and conf >= 0.8:
            result_var.set("âœ… å•Ÿå‹•æˆåŠŸï¼")
            return

# === è¾¨è­˜æŒ‡ä»¤ï¼ˆ20 ç§’å…§æ»‘å‹•è¦–çª—ï¼‰ ===
def listen_for_command():
    """
    åœ¨ timeout_command å…§ï¼Œæ¯ step_duration éŒ„ä¸€æ¬¡ chunkï¼Œ
    ä»¥ deque(window_length) ä½œæ»‘å‹•çª—å£ï¼ŒæŒçºŒæ¨è«–ä¸¦å„²å­˜æ‰€æœ‰ä¸­é–“æª”æ¡ˆã€‚
    å›å‚³æœ€çµ‚è¦åŸ·è¡Œçš„ command (æˆ– None)ã€‚
    """
    buf = deque(maxlen=int(step_duration * fs_command))  # æ»‘å‹•çª—å£ç·©è¡
    full_audio = []  # æ”¶é›†æ‰€æœ‰ chunk
    start = time.time()
    chunk_idx = 0  # åŸå§‹ chunk è¨ˆæ•¸
    window_idx = 0  # æ»‘å‹•çª—å£è¨ˆæ•¸
    candidate, cand_conf = None, 0.0  # å€™é¸æŒ‡ä»¤èˆ‡ä¿¡å¿ƒ

    result_var.set(f"âŒ› è¾¨è­˜é–‹å§‹ (0/{int(timeout_command)}s)")
    while time.time() - start < timeout_command:
        elapsed = time.time() - start
        result_var.set(f"âŒ› è¾¨è­˜ä¸­ï¼Œå‰© {timeout_command - elapsed:.1f}s")

        # éŒ„è£½ step_duration é•·åº¦çš„åŸå§‹ chunk
        chunk = record_chunk(fs_command, window_length)
        chunk_idx += 1
        full_audio.append(chunk)

        # å„²å­˜åŸå§‹ chunk
        chunk_path = os.path.join(test_dir, f"chunk_{chunk_idx:03d}.wav")
        write(chunk_path, fs_command, (chunk * 32767).astype(np.int16))
        print(f"ğŸ’¾ Saved chunk: {chunk_path}")

        # æ›´æ–°æ»‘å‹•ç·©è¡
        buf.extend(chunk)
        # ç·©è¡å°šæœªé”åˆ° window_length
        if len(buf) < buf.maxlen:
            continue

        # ç•¶ç·©è¡æ»¿ï¼Œå–å‡ºä¸€æ®µéŸ³è¨Šåš trimã€æ¨è«–
        window_idx += 1
        audio_window = np.array(buf)
        sig = trim_speech_from_array(audio_window, fs_command)
        if sig is None:
            continue

        input_path = os.path.join(test_dir, f"input_{window_idx:03d}.wav")
        write(input_path, fs_command, (sig * 32767).astype(np.int16))
        print(f"ğŸ’¾ Saved input window: {input_path}")

        cmd, conf = predict_command(sig, fs_command)
        print(f"[{elapsed:.1f}s] åµæ¸¬ {cmd} (conf={conf:.2f})")

        # éæ¿¾ä¸å¯åŸ·è¡Œæˆ–ä¿¡å¿ƒä¸è¶³
        if cmd in NON_EXECUTABLE_TAGS or conf < CONF_THRESHOLD:
            continue
        # å„ªå…ˆè¨˜éŒ„å¯åŸ·è¡Œå‘½ä»¤
        if cmd in EXECUTABLE_COMMANDS and candidate is None:
            candidate, cand_conf = cmd, conf
            result_var.set(f"âœ… å„ªå…ˆæŒ‡ä»¤ï¼š{cmd} ({conf:.2f})")
        elif candidate is None:
            candidate, cand_conf = cmd, conf
            result_var.set(f"âœ… åµæ¸¬æŒ‡ä»¤ï¼š{cmd} ({conf:.2f})")

    # 20 ç§’çµæŸï¼Œå„²å­˜å®Œæ•´éŸ³è¨Šä¸¦å›å‚³çµæœ
    full_array = np.concatenate(full_audio)
    full_path = os.path.join(test_dir, 'full_20s.wav')
    write(full_path, fs_command, (full_array * 32767).astype(np.int16))
    print(f"ğŸ’¾ Saved full segment: {full_path}")

    if candidate:
        result_var.set(f"ğŸš€ åŸ·è¡Œï¼š{candidate} ({cand_conf:.2f})")
        return candidate

    result_var.set("âŒ æ™‚é–“åˆ°ï¼Œæœªåµæ¸¬åˆ°æœ‰æ•ˆæŒ‡ä»¤")
    return None

# === ä¸»æµç¨‹ ===
def process():
    # å…ˆç­‰å¾…å•Ÿå‹•è©
    listen_for_activation()
    # è¾¨è­˜ä¸¦åŸ·è¡ŒæŒ‡ä»¤
    cmd = listen_for_command()
    if cmd:
        print(f"ğŸš€ åŸ·è¡Œå‘½ä»¤ï¼š{cmd}")
    else:
        print("âš ï¸ ç„¡å‘½ä»¤åŸ·è¡Œ")

# å•Ÿå‹•æ–°åŸ·è¡Œç·’ä»¥å…é˜»å¡ GUI
def start_process():
    threading.Thread(target=process, daemon=True).start()

# === å»ºç«‹ GUI ===
root = tk.Tk()
root.title("ğŸ¤ è²æ§ç³»çµ±")

result_var = tk.StringVar()  # ç”¨æ–¼é¡¯ç¤ºç‹€æ…‹æ–‡å­—
label = tk.Label(root, textvariable=result_var, font=("Arial", 16), fg="blue")
label.pack(pady=20)

btn = tk.Button(root, text="ğŸ™ï¸ å•Ÿå‹•è¾¨è­˜", font=("Arial", 14), command=start_process)
btn.pack(pady=10)

# æœªå¯¦ä½œçš„æ–°å¢æŒ‡ä»¤æŒ‰éˆ•
add_btn = tk.Button(root, text="â• æ–°å¢æŒ‡ä»¤ï¼ˆæœªå¯¦ä½œï¼‰", font=("Arial", 12))
add_btn.pack(pady=5)

root.mainloop()  # é€²å…¥ GUI äº‹ä»¶è¿´åœˆ
