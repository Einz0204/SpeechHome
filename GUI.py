import sounddevice as sd
import scipy.io.wavfile as wavfile
import librosa
import numpy as np
import tensorflow as tf
import tkinter as tk
import time
import threading
import os
from scipy.io.wavfile import write

# === åƒæ•¸è¨­å®š ===
fs_activation = 16000        # å•Ÿå‹•è©éšæ®µå–æ¨£ç‡
fs_command    = 32000        # æŒ‡ä»¤è¾¨è­˜éšæ®µå–æ¨£ç‡
duration      = 3            # æ¯æ¬¡éŒ„éŸ³ç§’æ•¸
record_file   = 'raw_record.wav'
trimmed_file  = 'trimmed_record.wav'
model_path    = os.path.join('classifier', 'cnn_model.h5')

# === ä¿¡å¿ƒåº¦ & æ¨™ç±¤è¨­å®š ===
CONF_THRESHOLD       = 0.85
EXECUTABLE_COMMANDS  = ["é–‹ç‡ˆ", "é—œç‡ˆ"]
NON_EXECUTABLE_TAGS  = ["UNKNOWN", "Noise"]

# === è¼‰å…¥æŒ‡ä»¤æ¨™ç±¤ ===
with open("classifier/labels.txt", "r", encoding="utf-8") as f:
    COMMANDS = [line.strip() for line in f.readlines()]

# === å…¨åŸŸä¸€æ¬¡è¼‰å…¥æ¨¡å‹ï¼ˆè·³é compileï¼Œä»¥æ¶ˆé™¤ warning ä¸¦åŠ å¿«æ¨è«–ï¼‰ ===
MODEL = tf.keras.models.load_model(model_path, compile=False)

# === é€šç”¨éŒ„éŸ³å‡½å¼ï¼ˆå¯æŒ‡å®šå–æ¨£ç‡ï¼‰ ===
def record_audio(sr):
    print(f"ğŸ™ï¸ éŒ„éŸ³ä¸­ï¼ˆ{sr//1000} kHz, {duration}sï¼‰...")
    audio = sd.rec(int(sr * duration), samplerate=sr, channels=1, dtype='int16')
    sd.wait()
    wavfile.write(record_file, sr, audio)
    print("âœ… éŒ„éŸ³å®Œæˆ")

# === å»é™¤éœéŸ³ä¸¦å›ºå®šé•·åº¦ ===
def trim_speech(filename, sr, target_duration=1.5):
    y, _ = librosa.load(filename, sr=sr)
    intervals = librosa.effects.split(y, top_db=20)
    if len(intervals) == 0:
        return None
    speech = np.concatenate([y[start:end] for start, end in intervals])
    target_len = int(target_duration * sr)
    if len(speech) < target_len:
        speech = np.pad(speech, (0, target_len - len(speech)))
    else:
        speech = speech[:target_len]
    return speech

# === MFCC è™•ç† ===
def fix_mfcc_length(mfcc, target_frames=32):
    if mfcc.shape[1] < target_frames:
        pad_width = target_frames - mfcc.shape[1]
        mfcc = np.pad(mfcc, ((0, 0), (0, pad_width)), mode='constant')
    else:
        mfcc = mfcc[:, :target_frames]
    return mfcc

# === æ¨¡å‹é æ¸¬ï¼ˆæ”¹ç”¨å…¨åŸŸ MODELï¼‰ ===
def predict_command(signal, sr):
    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=40)
    mfcc = fix_mfcc_length(mfcc, target_frames=32)
    mfcc = mfcc[..., np.newaxis]         # (40,32,1)
    mfcc = np.expand_dims(mfcc, axis=0)  # (1,40,32,1)

    pred = MODEL.predict(mfcc)
    idx  = np.argmax(pred)
    conf = float(pred[0][idx])
    return COMMANDS[idx], conf

# === ç­‰å¾…ã€Œå•Ÿå‹•ã€é—œéµè© ===
def listen_for_activation():
    result_var.set("ğŸ§ ç­‰å¾…ã€å•Ÿå‹•ã€æŒ‡ä»¤...")
    while True:
        record_audio(fs_activation)
        signal = trim_speech(record_file, fs_activation)
        if signal is None:
            continue
        result, conf = predict_command(signal, fs_activation)
        print(f"ğŸ“¡ åµæ¸¬åˆ° [{result}] ç½®ä¿¡åº¦: {conf:.2f}")
        if result == "å•Ÿå‹•" and conf >= 0.8:
            result_var.set("âœ… å•Ÿå‹•æˆåŠŸï¼Œè«‹ä¸‹æŒ‡ä»¤...")
            return

# === 10 ç§’å…§è¾¨è­˜å‘½ä»¤ ===
def listen_for_command(timeout=15):
    start = time.time()
    while time.time() - start < timeout:
        record_audio(fs_command)
        signal = trim_speech(record_file, fs_command)
        if signal is None:
            result_var.set("æˆ‘æ²’è½æ¸…æ¥šï¼Œè«‹å†èªªä¸€æ¬¡")
            continue

        # å„²å­˜è£å‰ªå¾ŒéŸ³æª”ï¼ˆéå¿…è¦ï¼Œå¯ä¾›é™¤éŒ¯ï¼‰
        write(trimmed_file, fs_command, (signal * 32767).astype(np.int16))

        result, conf = predict_command(signal, fs_command)
        print(f"ğŸ¯ åµæ¸¬ [{result}] ç½®ä¿¡åº¦: {conf:.2f}")

        # éåŸ·è¡Œæ¨™ç±¤
        if result in NON_EXECUTABLE_TAGS:
            result_var.set("æˆ‘æ²’è½æ¸…æ¥šï¼Œè«‹å†èªªä¸€æ¬¡")
            continue
        # ä¿¡å¿ƒåº¦é–€æª»
        if conf < CONF_THRESHOLD:
            result_var.set("æˆ‘æ²’è½æ¸…æ¥šï¼Œè«‹å†èªªä¸€æ¬¡")
            continue
        # å„ªå…ˆåŸ·è¡Œé–‹/é—œç‡ˆ
        if result in EXECUTABLE_COMMANDS:
            result_var.set(f"âœ… æŒ‡ä»¤ï¼š{result}\nä¿¡å¿ƒå€¼ï¼š{conf:.2f}")
            return result
        # å…¶ä»–æœ‰æ•ˆå‘½ä»¤
        result_var.set(f"âœ… æŒ‡ä»¤ï¼š{result}\nä¿¡å¿ƒå€¼ï¼š{conf:.2f}")
        return result

    result_var.set("âŒ› æŒ‡ä»¤è¶…æ™‚ï¼Œæœªæ”¶åˆ°æœ‰æ•ˆè¼¸å…¥")
    return None

# === ä¸»æµç¨‹ ===
def process():
    listen_for_activation()
    cmd = listen_for_command(timeout=10)
    if cmd:
        print(f"ğŸš€ åŸ·è¡Œå‘½ä»¤ï¼š{cmd}")
        # åœ¨æ­¤åŠ å…¥å°æ‡‰å‘½ä»¤çš„å¯¦éš›å‹•ä½œ
    else:
        print("âš ï¸ ç„¡æœ‰æ•ˆæŒ‡ä»¤")

def start_process():
    threading.Thread(target=process, daemon=True).start()

# === GUI ===
root = tk.Tk()
root.title("ğŸ¤ è²æ§ç³»çµ±")

result_var = tk.StringVar()
label = tk.Label(root, textvariable=result_var, font=("Arial", 16), fg="blue")
label.pack(pady=20)

btn = tk.Button(root, text="ğŸ™ï¸ å•Ÿå‹•èªéŸ³è¾¨è­˜", font=("Arial", 14), command=start_process)
btn.pack(pady=10)

add_btn = tk.Button(root, text="â• æ–°å¢æŒ‡ä»¤ï¼ˆæœªå¯¦ä½œï¼‰", font=("Arial", 12))
add_btn.pack(pady=5)

root.mainloop()
