import sounddevice as sd
import numpy as np
import tensorflow as tf
import tkinter as tk
import time
import threading
import os
from collections import deque
from scipy.io.wavfile import write
import librosa
import soundfile as sf
import queue

# === å…¨åŸŸåƒæ•¸ ===
fs_command = 16000
fs_activation = 16000
window_length = 2.0
step_duration = 0.2
timeout_command = 20.0
activation_dur = 3.0
record_file = 'raw.wav'
model_path = os.path.join('classifier', 'cnn_model.h5')
test_dir = 'test_inputs'

CONF_THRESHOLD = 0.85
EXECUTABLE_COMMANDS = ["é–‹ç‡ˆ", "é—œç‡ˆ"]
NON_EXECUTABLE_TAGS = ["UNKNOWN", "Noise"]

os.makedirs(test_dir, exist_ok=True)

with open("classifier/labels.txt", "r", encoding="utf-8") as f:
    COMMANDS = [l.strip() for l in f]

MODEL = tf.keras.models.load_model(model_path, compile=False)

audio_queue = queue.Queue()
running = False
start_time = None  # ğŸ•’ Producer é–‹å§‹é€è³‡æ–™æ™‚æœƒè¨­å®š
result_var = None  # GUI é¡¯ç¤ºç”¨

# === éŒ„éŸ³ ===
def record_chunk(sr, duration):
    audio = sd.rec(int(sr * duration), samplerate=sr, channels=1, dtype='int16')
    sd.wait()
    return audio.flatten().astype(np.float32) / 32767.0

# === èªéŸ³æ“·å–ï¼ˆVADï¼‰ ===
def trim_speech(signal, sr, target_dur=1.0):
    intervals = librosa.effects.split(signal, top_db=30)
    if len(intervals) == 0:
        return None
    y = np.concatenate([signal[start:end] for start, end in intervals])
    L = int(target_dur * sr)
    return y[:L] if len(y) >= L else np.pad(y, (0, L - len(y)))

# === MFCC ä¿®æ­£é•·åº¦ ===
def fix_mfcc_length(mfcc, target_frames=32):
    if mfcc.shape[1] < target_frames:
        return np.pad(mfcc, ((0, 0), (0, target_frames - mfcc.shape[1])), mode='constant')
    return mfcc[:, :target_frames]

# === æ¨¡å‹é æ¸¬ ===
def predict_command(signal, sr):
    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=40)
    mfcc = fix_mfcc_length(mfcc)
    mfcc = mfcc[..., np.newaxis]
    mfcc = np.expand_dims(mfcc, 0)
    pred = MODEL.predict(mfcc, verbose=0)[0]
    idx, conf = int(np.argmax(pred)), float(np.max(pred))
    return COMMANDS[idx], conf

# === å•Ÿå‹•è©è¾¨è­˜ ===
def listen_for_activation():
    result_var.set("ğŸ§ ç­‰å¾…ã€å•Ÿå‹•ã€â€¦ï¼ˆä¸è¨ˆå…¥è¾¨è­˜æ™‚é–“ï¼‰")
    root.update()
    while True:
        audio = record_chunk(fs_activation, activation_dur)
        write("activation.wav", fs_activation, (audio * 32767).astype(np.int16))
        sig = trim_speech(audio, fs_activation, target_dur=1.5)
        if sig is None:
            continue
        cmd, conf = predict_command(sig, fs_activation)
        if cmd == "å•Ÿå‹•" and conf >= 0.3:
            result_var.set("âœ… å•Ÿå‹•æˆåŠŸï¼")
            root.update()
            return

# === Producerï¼ˆæ“·å–2ç§’ clip + VADæˆ1ç§’ï¼‰===
def producer_loop():
    global running, start_time
    fs = fs_command
    window_size = int(fs * window_length)
    buffer = deque(maxlen=window_size)
    clip_idx = 0
    input_idx = 0

    # åˆå§‹åŒ– buffer
    while len(buffer) < window_size:
        chunk = record_chunk(fs, 0.05)
        buffer.extend(chunk)

    while running:
        if len(buffer) < window_size:
            time.sleep(step_duration)
            continue

        window = np.array(buffer)[-window_size:]
        clip_idx += 1
        clip_path = os.path.join(test_dir, f"clip_{clip_idx:03d}.wav")
        write(clip_path, fs, (window * 32767).astype(np.int16))

        input_sig = trim_speech(window, fs, target_dur=1.0)
        if input_sig is not None:
            input_idx += 1
            input_path = os.path.join(test_dir, f"input_{input_idx:03d}.wav")
            write(input_path, fs, (input_sig * 32767).astype(np.int16))

            if start_time is None:
                start_time = time.time()  # âœ… çœŸæ­£è¾¨è­˜æ™‚é–“èµ·é»

            audio_queue.put((input_sig, input_idx))

        chunk = record_chunk(fs, 0.05)
        buffer.extend(chunk)
        time.sleep(step_duration)

# === Consumerï¼ˆæ¨è«– + å€’æ•¸é¡¯ç¤ºï¼‰===
def consumer_loop():
    global running, start_time
    candidate, cand_conf = None, 0.0

    # ç­‰å¾… producer è¨­å®š start_time
    while start_time is None and running:
        time.sleep(0.01)

    while running or not audio_queue.empty():
        elapsed = time.time() - start_time
        remaining = max(0, timeout_command - elapsed)

        if remaining <= 0:
            break  # â± æ™‚é–“åˆ°ï¼Œé›¢é–‹ consumerï¼Œproducer ä¹Ÿæœƒè‡ªå‹•çµæŸ

        try:
            signal, input_idx = audio_queue.get(timeout=0.5)
        except queue.Empty:
            continue

        result_var.set(f"âŒ› å‰©é¤˜æ™‚é–“ï¼š{remaining:.1f}s")
        root.update()

        cmd, conf = predict_command(signal, fs_command)
        print(f"[{elapsed:.1f}s] åµæ¸¬ {cmd} (conf={conf:.2f})")

        if cmd in NON_EXECUTABLE_TAGS or conf < CONF_THRESHOLD:
            continue

        if cmd in EXECUTABLE_COMMANDS and candidate is None:
            candidate, cand_conf = cmd, conf
            result_var.set(f"âœ… å„ªå…ˆæŒ‡ä»¤ï¼š{cmd} ({conf:.2f})")
            root.update()
        elif candidate is None:
            candidate, cand_conf = cmd, conf
            result_var.set(f"âœ… åµæ¸¬æŒ‡ä»¤ï¼š{cmd} ({conf:.2f})")
            root.update()

    # æ”¶å°¾
    if candidate:
        result_var.set(f"ğŸš€ åŸ·è¡Œï¼š{candidate} ({cand_conf:.2f})")
        print(f"ğŸš€ åŸ·è¡Œå‘½ä»¤ï¼š{candidate}")
    else:
        result_var.set("âŒ æ™‚é–“åˆ°ï¼Œæœªåµæ¸¬åˆ°æœ‰æ•ˆæŒ‡ä»¤")
        print("âš ï¸ ç„¡å‘½ä»¤åŸ·è¡Œ")

    running = False

# === ä¸»æµç¨‹æ§åˆ¶ ===
def process():
    global running, start_time, timeout_command

    # é¡¯ç¤ºç­‰å¾…å•Ÿå‹•è©ï¼ˆä¸»ç·šç¨‹ï¼‰
    result_var.set("ğŸ§ ç­‰å¾…ã€å•Ÿå‹•ã€â€¦ï¼ˆä¸è¨ˆå…¥è¾¨è­˜æ™‚é–“ï¼‰")
    root.update()

    def background_activation():
        listen_for_activation()

        # å•Ÿå‹•æˆåŠŸå¾Œï¼Œæ’å…¥ä¸»ç·šç¨‹è™•ç†å¾ŒçºŒ
        def start_after_activation():
            global running, start_time, timeout_command
            result_var.set("â³ è¾¨è­˜ä¸­â€¦")
            root.update()

            start_time = None
            running = True
            timeout_command = 20.0  # âœ… åœ¨é€™è£¡é‡è¨­å€’æ•¸ç§’æ•¸

            threading.Thread(target=producer_loop, daemon=True).start()
            threading.Thread(target=consumer_loop, daemon=True).start()

        root.after(100, start_after_activation)

    threading.Thread(target=background_activation, daemon=True).start()

# === GUI å•Ÿå‹• ===
def start_process():
    threading.Thread(target=process, daemon=True).start()

root = tk.Tk()
root.title("ğŸ¤ è²æ§ç³»çµ±")

result_var = tk.StringVar()
label = tk.Label(root, textvariable=result_var, font=("Arial", 16), fg="blue")
label.pack(pady=20)

btn = tk.Button(root, text="ğŸ™ï¸ å•Ÿå‹•è¾¨è­˜", font=("Arial", 14), command=start_process)
btn.pack(pady=10)

add_btn = tk.Button(root, text="â• æ–°å¢æŒ‡ä»¤ï¼ˆæœªå¯¦ä½œï¼‰", font=("Arial", 12))
add_btn.pack(pady=5)

root.mainloop()
